"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_01=globalThis.webpackChunkphysical_ai_humanoid_robotics_01||[]).push([[64],{9571:i=>{i.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"mainSidebar":[{"type":"link","href":"/physical-ai-humanoid-robotics/docs/preface","label":"Preface","docId":"preface","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/intro-physical-ai","label":"Introduction to Physical AI","docId":"intro-physical-ai","unlisted":false},{"type":"category","label":"Module 1: ROS 2 (The Robotic Nervous System)","collapsible":true,"collapsed":false,"items":[{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-1-ros2/ros2-fundamentals","label":"ROS 2 Fundamentals","docId":"module-1-ros2/ros2-fundamentals","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-1-ros2/nodes-topics-services","label":"Nodes, Topics, and Services","docId":"module-1-ros2/nodes-topics-services","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-1-ros2/building-packages-python","label":"Building ROS 2 Packages with Python","docId":"module-1-ros2/building-packages-python","unlisted":false}]},{"type":"category","label":"Module 2: Gazebo & Unity (The Digital Twin)","collapsible":true,"collapsed":false,"items":[{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-2-gazebo/intro-gazebo","label":"Introduction to Gazebo","docId":"module-2-gazebo/intro-gazebo","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-2-gazebo/unity-robotics","label":"Unity for Robotics","docId":"module-2-gazebo/unity-robotics","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-2-gazebo/simulation-best-practices","label":"Simulation Best Practices","docId":"module-2-gazebo/simulation-best-practices","unlisted":false}]},{"type":"category","label":"Module 3: NVIDIA Isaac (The AI-Robot Brain)","collapsible":true,"collapsed":false,"items":[{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-3-isaac/intro-isaac","label":"Introduction to NVIDIA Isaac","docId":"module-3-isaac/intro-isaac","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-3-isaac/isaac-sim","label":"Isaac Sim for Robotics","docId":"module-3-isaac/isaac-sim","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-3-isaac/isaac-gym-rl","label":"Reinforcement Learning with Isaac Gym","docId":"module-3-isaac/isaac-gym-rl","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-3-isaac/isaac-sdk-overview","label":"Isaac Platform Architecture","docId":"module-3-isaac/isaac-sdk-overview","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-3-isaac/ai-powered-perception","label":"AI-Powered Perception","docId":"module-3-isaac/ai-powered-perception","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-3-isaac/reinforcement-learning","label":"Advanced RL and Sim-to-Real Transfer","docId":"module-3-isaac/reinforcement-learning","unlisted":false}]},{"type":"category","label":"Module 4: VLA (Vision-Language-Action)","collapsible":true,"collapsed":false,"items":[{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-4-vla/intro-vla","label":"Introduction to VLA Models","docId":"module-4-vla/intro-vla","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-4-vla/vla-architectures","label":"VLA Architectures: RT-1, RT-2, PaLM-E","docId":"module-4-vla/vla-architectures","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-4-vla/vla-training-deployment","label":"Training and Deploying VLA Systems","docId":"module-4-vla/vla-training-deployment","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-4-vla/voice-to-action","label":"Voice-to-Action with OpenAI Whisper","docId":"module-4-vla/voice-to-action","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-4-vla/cognitive-planning","label":"Cognitive Planning with LLMs","docId":"module-4-vla/cognitive-planning","unlisted":false},{"type":"link","href":"/physical-ai-humanoid-robotics/docs/module-4-vla/multimodal-interaction","label":"Multi-modal Interaction (Speech, Gesture, Vision)","docId":"module-4-vla/multimodal-interaction","unlisted":false}]}]},"docs":{"intro-physical-ai":{"id":"intro-physical-ai","title":"Introduction to Physical AI","description":"Physical AI Concept","sidebar":"mainSidebar"},"module-1-ros2/building-packages-python":{"id":"module-1-ros2/building-packages-python","title":"Building ROS 2 Packages with Python","description":"Prerequisites","sidebar":"mainSidebar"},"module-1-ros2/nodes-topics-services":{"id":"module-1-ros2/nodes-topics-services","title":"Nodes, Topics, and Services","description":"Prerequisites","sidebar":"mainSidebar"},"module-1-ros2/ros2-fundamentals":{"id":"module-1-ros2/ros2-fundamentals","title":"ROS 2 Fundamentals","description":"ROS 2 Robotics Platform","sidebar":"mainSidebar"},"module-2-gazebo/intro-gazebo":{"id":"module-2-gazebo/intro-gazebo","title":"Introduction to Gazebo","description":"Learn how to set up and use Gazebo Garden for robot simulation with ROS 2 Humble","sidebar":"mainSidebar"},"module-2-gazebo/simulation-best-practices":{"id":"module-2-gazebo/simulation-best-practices","title":"Simulation Best Practices","description":"Learn best practices for robot simulation testing, performance optimization, and troubleshooting common issues","sidebar":"mainSidebar"},"module-2-gazebo/unity-robotics":{"id":"module-2-gazebo/unity-robotics","title":"Unity for Robotics","description":"Learn how to use Unity 2022 LTS and Unity Robotics Hub for robot visualization and simulation with ROS 2","sidebar":"mainSidebar"},"module-3-isaac/ai-powered-perception":{"id":"module-3-isaac/ai-powered-perception","title":"AI-Powered Perception","description":"Implement object detection, segmentation, pose estimation, and depth perception for robotic manipulation using Isaac Sim","sidebar":"mainSidebar"},"module-3-isaac/intro-isaac":{"id":"module-3-isaac/intro-isaac","title":"Introduction to NVIDIA Isaac","description":"Learn about NVIDIA Isaac Sim and Isaac Gym for GPU-accelerated robotics simulation and reinforcement learning","sidebar":"mainSidebar"},"module-3-isaac/isaac-gym-rl":{"id":"module-3-isaac/isaac-gym-rl","title":"Reinforcement Learning with Isaac Gym","description":"Learn to train robot policies using GPU-accelerated parallel RL environments in Isaac Gym","sidebar":"mainSidebar"},"module-3-isaac/isaac-sdk-overview":{"id":"module-3-isaac/isaac-sdk-overview","title":"Isaac Platform Architecture","description":"Deep dive into NVIDIA Isaac platform components, USD workflows, and integration with ROS 2 for production robotics","sidebar":"mainSidebar"},"module-3-isaac/isaac-sim":{"id":"module-3-isaac/isaac-sim","title":"Isaac Sim for Robotics","description":"Learn to create robotic simulations in Isaac Sim with USD scenes, URDF import, sensor simulation, and ROS 2 integration","sidebar":"mainSidebar"},"module-3-isaac/reinforcement-learning":{"id":"module-3-isaac/reinforcement-learning","title":"Advanced RL and Sim-to-Real Transfer","description":"Master advanced reinforcement learning techniques, multi-agent systems, and sim-to-real transfer strategies for deploying trained policies on physical robots","sidebar":"mainSidebar"},"module-4-vla/cognitive-planning":{"id":"module-4-vla/cognitive-planning","title":"Cognitive Planning with LLMs","description":"Use large language models for high-level task planning, reasoning, and decision-making in autonomous robotics","sidebar":"mainSidebar"},"module-4-vla/intro-vla":{"id":"module-4-vla/intro-vla","title":"Introduction to VLA Models","description":"Learn about Vision-Language-Action (VLA) models and their role in cutting-edge robotic control","sidebar":"mainSidebar"},"module-4-vla/multimodal-interaction":{"id":"module-4-vla/multimodal-interaction","title":"Multi-modal Interaction (Speech, Gesture, Vision)","description":"Integrate speech, gesture recognition, and vision to create natural human-robot interaction systems","sidebar":"mainSidebar"},"module-4-vla/vla-architectures":{"id":"module-4-vla/vla-architectures","title":"VLA Architectures: RT-1, RT-2, PaLM-E","description":"Deep dive into state-of-the-art Vision-Language-Action architectures including RT-1, RT-2, and PaLM-E","sidebar":"mainSidebar"},"module-4-vla/vla-training-deployment":{"id":"module-4-vla/vla-training-deployment","title":"Training and Deploying VLA Systems","description":"Learn how to train, fine-tune, and deploy Vision-Language-Action models for real-world robotics applications","sidebar":"mainSidebar"},"module-4-vla/voice-to-action":{"id":"module-4-vla/voice-to-action","title":"Voice-to-Action with OpenAI Whisper","description":"Implement voice-controlled robotics using speech recognition and natural language processing","sidebar":"mainSidebar"},"preface":{"id":"preface","title":"Preface","description":"Robotics Overview","sidebar":"mainSidebar"}}}}')}}]);