"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_01=globalThis.webpackChunkphysical_ai_humanoid_robotics_01||[]).push([[724],{8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>a});var r=i(6540);const s={},t=r.createContext(s);function o(n){const e=r.useContext(t);return r.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:o(n.components),r.createElement(t.Provider,{value:e},n.children)}},8682:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module-3-isaac/isaac-sim","title":"Isaac Sim for Robotics","description":"Learn to create robotic simulations in Isaac Sim with USD scenes, URDF import, sensor simulation, and ROS 2 integration","source":"@site/docs/module-3-isaac/isaac-sim.md","sourceDirName":"module-3-isaac","slug":"/module-3-isaac/isaac-sim","permalink":"/physical-ai-humanoid-robotics/docs/module-3-isaac/isaac-sim","draft":false,"unlisted":false,"editUrl":"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/module-3-isaac/isaac-sim.md","tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2,"title":"Isaac Sim for Robotics","description":"Learn to create robotic simulations in Isaac Sim with USD scenes, URDF import, sensor simulation, and ROS 2 integration"},"sidebar":"mainSidebar","previous":{"title":"Introduction to NVIDIA Isaac","permalink":"/physical-ai-humanoid-robotics/docs/module-3-isaac/intro-isaac"},"next":{"title":"Reinforcement Learning with Isaac Gym","permalink":"/physical-ai-humanoid-robotics/docs/module-3-isaac/isaac-gym-rl"}}');var s=i(4848),t=i(8453);const o={sidebar_position:2,title:"Isaac Sim for Robotics",description:"Learn to create robotic simulations in Isaac Sim with USD scenes, URDF import, sensor simulation, and ROS 2 integration"},a="Isaac Sim for Robotics",l={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Introduction",id:"introduction",level:2},{value:"Creating Simulation Scenes",id:"creating-simulation-scenes",level:2},{value:"USD Scene Structure",id:"usd-scene-structure",level:3},{value:"Creating a Scene in the GUI",id:"creating-a-scene-in-the-gui",level:3},{value:"Creating Scenes Programmatically with Python",id:"creating-scenes-programmatically-with-python",level:3},{value:"Importing Robot Models",id:"importing-robot-models",level:2},{value:"URDF Import Workflow",id:"urdf-import-workflow",level:3},{value:"Importing a Robot via GUI",id:"importing-a-robot-via-gui",level:3},{value:"Importing a Robot via Python API",id:"importing-a-robot-via-python-api",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:2},{value:"RGB Camera",id:"rgb-camera",level:3},{value:"Depth Camera",id:"depth-camera",level:3},{value:"LiDAR (LIDAR) Sensor",id:"lidar-lidar-sensor",level:3},{value:"IMU (Inertial Measurement Unit)",id:"imu-inertial-measurement-unit",level:3},{value:"ROS 2 Integration",id:"ros-2-integration",level:2},{value:"Setting Up ROS 2 Bridge",id:"setting-up-ros-2-bridge",level:3},{value:"ROS 2 Control Example (Python)",id:"ros-2-control-example-python",level:3},{value:"Synthetic Data Generation",id:"synthetic-data-generation",level:2},{value:"Example: Generate RGB + Semantic Segmentation Data",id:"example-generate-rgb--semantic-segmentation-data",level:3},{value:"Hands-On Exercises",id:"hands-on-exercises",level:2},{value:"Exercise 1: Create a Custom Scene",id:"exercise-1-create-a-custom-scene",level:3},{value:"Exercise 2: Import a Robot URDF",id:"exercise-2-import-a-robot-urdf",level:3},{value:"Exercise 3: Add a Camera Sensor",id:"exercise-3-add-a-camera-sensor",level:3},{value:"Exercise 4: Publish Camera Data to ROS 2",id:"exercise-4-publish-camera-data-to-ros-2",level:3},{value:"Exercise 5: Collect Synthetic Training Data",id:"exercise-5-collect-synthetic-training-data",level:3},{value:"Key Takeaways",id:"key-takeaways",level:2},{value:"Navigation",id:"navigation",level:2}];function d(n){const e={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"isaac-sim-for-robotics",children:"Isaac Sim for Robotics"})}),"\n",(0,s.jsx)(e.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsx)(e.p,{children:"Before starting this chapter, you should have:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"\u2705 Completed Chapter 1: Introduction to NVIDIA Isaac"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Isaac Sim 2023.1.0 (or newer) installed and verified"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 NVIDIA RTX/GTX GPU (6GB+ VRAM) with updated drivers"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 ROS 2 Humble installed on Ubuntu 22.04 (for ROS 2 integration sections)"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Basic understanding of USD (Universal Scene Description) concepts"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Python programming experience"}),"\n",(0,s.jsx)(e.li,{children:"\u2705 Familiarity with robotics concepts (URDF, sensors, coordinate frames)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Estimated Reading Time"}),": 20-25 minutes"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"introduction",children:"Introduction"}),"\n",(0,s.jsx)(e.p,{children:'Creating realistic robotic simulations requires more than just loading a robot model and pressing "Play." Professional robotics development demands precise control over scene composition, physics parameters, sensor configurations, and integration with external frameworks like ROS 2. Isaac Sim provides powerful tools for all of these tasks, leveraging the USD (Universal Scene Description) format and NVIDIA\'s OmniGraph visual scripting system.'}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Isaac Sim Capabilities"}),": Isaac Sim goes beyond traditional simulators by offering:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Photorealistic Rendering"}),": RTX ray-traced graphics for testing computer vision algorithms under realistic lighting conditions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Synthetic Data Generation"}),": Automated creation of labeled datasets (RGB, depth, semantic segmentation, bounding boxes) for training ML models"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Domain Randomization"}),": Randomize lighting, textures, object positions, and physics parameters to improve sim-to-real transfer"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Scalable Workflows"}),": From single robot prototyping to thousand-robot parallel simulations for RL training"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Chapter Goals"}),": By the end of this chapter, you will create custom simulation scenes using USD, import robot URDF models into Isaac Sim, configure realistic sensors (cameras, LiDAR, IMU), integrate Isaac Sim with ROS 2 via OmniGraph, and generate synthetic training data. You'll develop the skills to build complete robotic simulation environments tailored to your research or product development needs."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Learning Objectives"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Understand USD scene composition (stages, prims, layers, variants)"}),"\n",(0,s.jsx)(e.li,{children:"Create simulation scenes with environments, lighting, and physics"}),"\n",(0,s.jsx)(e.li,{children:"Import robot URDF models and configure articulation properties"}),"\n",(0,s.jsx)(e.li,{children:"Add and configure sensors (RGB cameras, depth cameras, LiDAR, IMU)"}),"\n",(0,s.jsx)(e.li,{children:"Set up ROS 2 communication using OmniGraph visual scripting"}),"\n",(0,s.jsx)(e.li,{children:"Generate synthetic sensor data for machine learning workflows"}),"\n",(0,s.jsx)(e.li,{children:"Control robots in Isaac Sim via ROS 2 topics and Python scripts"}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"creating-simulation-scenes",children:"Creating Simulation Scenes"}),"\n",(0,s.jsxs)(e.p,{children:["Isaac Sim uses ",(0,s.jsx)(e.strong,{children:"USD (Universal Scene Description)"})," as its native scene format. Understanding USD fundamentals is essential for building complex simulations."]}),"\n",(0,s.jsx)(e.h3,{id:"usd-scene-structure",children:"USD Scene Structure"}),"\n",(0,s.jsxs)(e.p,{children:["A ",(0,s.jsx)(e.strong,{children:"USD Stage"})," is the top-level container for a simulation scene. It consists of ",(0,s.jsx)(e.strong,{children:"Prims"})," (primitives), which represent objects, lights, cameras, and other scene elements."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"USD Hierarchy Example"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"/World (Xform - root prim)\n\u251c\u2500\u2500 /World/GroundPlane (Mesh - floor)\n\u251c\u2500\u2500 /World/Sun (DistantLight - directional light)\n\u251c\u2500\u2500 /World/Camera (Camera - viewport)\n\u251c\u2500\u2500 /World/Robot (Xform - robot root)\n\u2502   \u251c\u2500\u2500 /World/Robot/base_link (RigidBody)\n\u2502   \u251c\u2500\u2500 /World/Robot/wheel_left (RigidBody + Joint)\n\u2502   \u2514\u2500\u2500 /World/Robot/wheel_right (RigidBody + Joint)\n\u2514\u2500\u2500 /World/Obstacles (Xform - obstacle container)\n    \u251c\u2500\u2500 /World/Obstacles/Box1 (Cube)\n    \u2514\u2500\u2500 /World/Obstacles/Sphere1 (Sphere)\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Key Concepts"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Prim"}),": A scene element (object, light, camera, etc.)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Xform"}),": Transform prim that groups child prims and defines their coordinate frame"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Mesh"}),": Visual geometry (rendered but no physics)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"RigidBody"}),": Physics-enabled object that responds to forces and collisions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint"}),": Connects two rigid bodies with constraints (revolute, prismatic, fixed, etc.)"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"creating-a-scene-in-the-gui",children:"Creating a Scene in the GUI"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 1: Create a New Stage"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Open Isaac Sim"}),"\n",(0,s.jsxs)(e.li,{children:["Go to ",(0,s.jsx)(e.strong,{children:"File \u2192 New"})]}),"\n",(0,s.jsx)(e.li,{children:"A blank USD stage is created (empty viewport)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 2: Add a Ground Plane"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["In the ",(0,s.jsx)(e.strong,{children:"Create"})," menu, select ",(0,s.jsx)(e.strong,{children:"Physics \u2192 Ground Plane"})]}),"\n",(0,s.jsx)(e.li,{children:"A large plane appears at the origin (represents the floor)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 3: Add Lighting"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Go to ",(0,s.jsx)(e.strong,{children:"Create \u2192 Light \u2192 Distant Light"})," (represents the sun)"]}),"\n",(0,s.jsxs)(e.li,{children:["In the ",(0,s.jsx)(e.strong,{children:"Property"})," panel, set:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Intensity"}),": ",(0,s.jsx)(e.code,{children:"3000"})," (brightness)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Angle"}),": ",(0,s.jsx)(e.code,{children:"0.53"})," (sun angular diameter)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Color"}),": White ",(0,s.jsx)(e.code,{children:"(1.0, 1.0, 1.0)"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 4: Add a Physics-Enabled Object"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Go to ",(0,s.jsx)(e.strong,{children:"Create \u2192 Mesh \u2192 Cube"})]}),"\n",(0,s.jsxs)(e.li,{children:["In the ",(0,s.jsx)(e.strong,{children:"Property"})," panel, set ",(0,s.jsx)(e.strong,{children:"Position"}),": ",(0,s.jsx)(e.code,{children:"(0, 0, 1.0)"})," (1 meter above ground)"]}),"\n",(0,s.jsxs)(e.li,{children:["Right-click the cube in the ",(0,s.jsx)(e.strong,{children:"Stage"})," panel \u2192 ",(0,s.jsx)(e.strong,{children:"Add \u2192 Physics \u2192 Rigid Body with Colliders Preset"})]}),"\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"Play"}),": The cube falls due to gravity"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 5: Save the Scene"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Go to ",(0,s.jsx)(e.strong,{children:"File \u2192 Save As"})]}),"\n",(0,s.jsxs)(e.li,{children:["Save as ",(0,s.jsx)(e.code,{children:"my_first_scene.usd"})," in your workspace directory"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"creating-scenes-programmatically-with-python",children:"Creating Scenes Programmatically with Python"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from isaacsim import SimulationApp\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.objects import DynamicCuboid, DynamicSphere\nfrom omni.isaac.core.utils.prims import create_prim\nimport numpy as np\n\n# Create world\nworld = World(stage_units_in_meters=1.0)\nworld.scene.add_default_ground_plane()\n\n# Add a cube\ncube = world.scene.add(\n    DynamicCuboid(\n        prim_path="/World/Cube",\n        position=np.array([0, 0, 0.5]),\n        size=np.array([0.3, 0.3, 0.3]),\n        color=np.array([1.0, 0.0, 0.0])  # Red\n    )\n)\n\n# Add a sphere\nsphere = world.scene.add(\n    DynamicSphere(\n        prim_path="/World/Sphere",\n        position=np.array([1.0, 0, 0.5]),\n        radius=0.2,\n        color=np.array([0.0, 0.0, 1.0])  # Blue\n    )\n)\n\n# Add directional light (sun)\ncreate_prim(\n    prim_path="/World/Sun",\n    prim_type="DistantLight",\n    attributes={"intensity": 3000, "angle": 0.53}\n)\n\n# Reset and run simulation\nworld.reset()\n\nfor i in range(500):\n    world.step(render=True)\n\nsimulation_app.close()\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Benefits of Programmatic Scene Creation"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Reproducibility"}),": Scenes are defined in code, making experiments reproducible"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Automation"}),": Generate thousands of randomized scenes for data augmentation"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Version Control"}),": Track scene changes with Git instead of binary USD files"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"importing-robot-models",children:"Importing Robot Models"}),"\n",(0,s.jsx)(e.p,{children:"Isaac Sim can import robot models defined in URDF (standard ROS format) and convert them to USD with physics and rendering."}),"\n",(0,s.jsx)(e.h3,{id:"urdf-import-workflow",children:"URDF Import Workflow"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-mermaid",children:"flowchart LR\n    A[URDF File<br/>robot.urdf] --\x3e B[Isaac Sim<br/>URDF Importer]\n    B --\x3e C[USD Conversion]\n    C --\x3e D[Articulation<br/>Configuration]\n    D --\x3e E[Physics Properties<br/>Masses/Inertias]\n    E --\x3e F[Visual Materials<br/>Textures/Colors]\n    F --\x3e G[USD Robot<br/>Prim Hierarchy]\n\n    style A fill:#2196F3,stroke:#1565C0,color:#fff\n    style G fill:#4CAF50,stroke:#2E7D32,color:#fff\n"})}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.em,{children:"Figure 1: URDF import workflow in Isaac Sim. The URDF Importer converts ROS robot descriptions to USD format with physics-enabled articulations."})}),"\n",(0,s.jsx)(e.h3,{id:"importing-a-robot-via-gui",children:"Importing a Robot via GUI"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 1: Open URDF Importer"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["In Isaac Sim, go to ",(0,s.jsx)(e.strong,{children:"Isaac Utils \u2192 Workflows \u2192 URDF Importer"})]}),"\n",(0,s.jsx)(e.li,{children:"A dialog window appears"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 2: Select URDF File"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"Browse"}),' next to "Input File"']}),"\n",(0,s.jsxs)(e.li,{children:["Navigate to your robot's URDF file (e.g., ",(0,s.jsx)(e.code,{children:"/opt/ros/humble/share/turtlebot3_description/urdf/turtlebot3_burger.urdf"}),")"]}),"\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"Open"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 3: Configure Import Settings"})}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Import Options"}),":","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["\u2705 ",(0,s.jsx)(e.strong,{children:"Fix Base Link"}),": Check if the robot should be fixed to the ground (for manipulators)"]}),"\n",(0,s.jsxs)(e.li,{children:["\u2705 ",(0,s.jsx)(e.strong,{children:"Merge Fixed Joints"}),": Simplifies the model by combining fixed links"]}),"\n",(0,s.jsxs)(e.li,{children:["\u2705 ",(0,s.jsx)(e.strong,{children:"Self Collision"}),": Enable collision detection between robot parts"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint Drive Type"}),": Choose ",(0,s.jsx)(e.code,{children:"Position"})," (default) for position-controlled joints"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Output Directory"}),": Select where to save the generated USD file"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 4: Import"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"Import"})]}),"\n",(0,s.jsx)(e.li,{children:"Isaac Sim converts URDF \u2192 USD (may take 10-60 seconds)"}),"\n",(0,s.jsx)(e.li,{children:"The robot appears in the viewport"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 5: Inspect the Robot"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["In the ",(0,s.jsx)(e.strong,{children:"Stage"})," panel, expand the robot prim hierarchy"]}),"\n",(0,s.jsxs)(e.li,{children:["Select a joint (e.g., ",(0,s.jsx)(e.code,{children:"/World/TurtleBot3/wheel_left_joint"}),")"]}),"\n",(0,s.jsxs)(e.li,{children:["In the ",(0,s.jsx)(e.strong,{children:"Property"})," panel, view:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint Type"}),": Continuous (for wheels), Revolute (for arms), etc."]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint Limits"}),": Min/max angles"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Joint Drive"}),": Target position, velocity, stiffness, damping"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"importing-a-robot-via-python-api",children:"Importing a Robot via Python API"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from isaacsim import SimulationApp\nsimulation_app = SimulationApp({"headless": False})\n\nfrom omni.isaac.core import World\nfrom omni.isaac.core.utils.stage import add_reference_to_stage\nfrom omni.isaac.core.articulations import Articulation\nimport numpy as np\n\n# Create world\nworld = World()\nworld.scene.add_default_ground_plane()\n\n# Import URDF (automatically converts to USD)\nfrom omni.importer.urdf import _urdf\nurdf_interface = _urdf.acquire_urdf_interface()\n\n# Import robot from URDF path\nrobot_prim_path = urdf_interface.parse_urdf(\n    urdf_path="/opt/ros/humble/share/turtlebot3_description/urdf/turtlebot3_burger.urdf",\n    robot_name="TurtleBot3",\n    dest_path="/World"\n)\n\n# Create an Articulation object to control the robot\nrobot = world.scene.add(\n    Articulation(\n        prim_path="/World/TurtleBot3",\n        name="turtlebot3"\n    )\n)\n\n# Reset world to initialize physics\nworld.reset()\n\n# Get joint information\nnum_joints = robot.num_dof\nprint(f"Robot has {num_joints} degrees of freedom")\nprint(f"Joint names: {robot.dof_names}")\n\n# Set joint positions (example: rotate wheels)\nrobot.set_joint_positions(np.array([0.0, 0.0]))  # Wheel positions in radians\n\n# Run simulation\nfor i in range(1000):\n    # Apply joint velocities (move forward)\n    robot.set_joint_velocities(np.array([2.0, 2.0]))  # rad/s\n    world.step(render=True)\n\nsimulation_app.close()\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Key Articulation API Methods"}),":"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robot.num_dof"}),": Number of controllable joints"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robot.dof_names"}),": List of joint names"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robot.get_joint_positions()"}),": Current joint angles/positions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robot.set_joint_positions(positions)"}),": Command joint positions"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robot.set_joint_velocities(velocities)"}),": Command joint velocities"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"robot.set_joint_efforts(efforts)"}),": Apply torques/forces to joints"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,s.jsx)(e.p,{children:"Isaac Sim provides realistic sensor simulations for cameras, LiDAR, IMU, force/torque sensors, and contact sensors."}),"\n",(0,s.jsx)(e.h3,{id:"rgb-camera",children:"RGB Camera"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Adding a Camera via GUI"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["In the ",(0,s.jsx)(e.strong,{children:"Stage"})," panel, right-click your robot \u2192 ",(0,s.jsx)(e.strong,{children:"Create \u2192 Camera"})]}),"\n",(0,s.jsx)(e.li,{children:"Position the camera (e.g., attach to robot's head link)"}),"\n",(0,s.jsxs)(e.li,{children:["In ",(0,s.jsx)(e.strong,{children:"Property"})," panel, configure:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Focal Length"}),": 24mm (wide-angle) or 50mm (standard)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Horizontal Aperture"}),": 20.955mm (full-frame sensor)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Focus Distance"}),": Auto"]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["Go to ",(0,s.jsx)(e.strong,{children:"Window \u2192 Render Settings"})," \u2192 Enable ",(0,s.jsx)(e.strong,{children:"RTX Real-Time"})," for ray-traced rendering"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Python API for RGB Camera"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\n\n# Create a camera\ncamera = Camera(\n    prim_path="/World/Camera",\n    position=np.array([2.0, 0, 1.5]),  # 2m in front, 1.5m high\n    frequency=30,  # 30 Hz capture rate\n    resolution=(640, 480),\n    orientation=np.array([1, 0, 0, 0])  # Quaternion (w, x, y, z)\n)\n\ncamera.initialize()\n\n# Capture an image\ncamera.add_motion_vectors_to_frame()  # Optional: add motion vectors\nrgb_data = camera.get_rgba()  # RGBA image as numpy array (480, 640, 4)\n\n# Save image\nimport cv2\ncv2.imwrite("camera_capture.png", rgb_data[:, :, :3])  # Drop alpha channel\n'})}),"\n",(0,s.jsx)(e.h3,{id:"depth-camera",children:"Depth Camera"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Depth Camera Configuration"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from omni.isaac.sensor import Camera\n\ndepth_camera = Camera(\n    prim_path="/World/DepthCamera",\n    position=np.array([2.0, 0, 1.5]),\n    frequency=10,  # 10 Hz (depth is computationally expensive)\n    resolution=(640, 480)\n)\n\ndepth_camera.initialize()\ndepth_camera.add_depth_to_frame()  # Enable depth output\n\n# Get depth image\ndepth_data = depth_camera.get_depth()  # Depth in meters (480, 640)\n\n# Visualize depth (convert to grayscale image)\ndepth_normalized = (depth_data / depth_data.max() * 255).astype(np.uint8)\ncv2.imwrite("depth_map.png", depth_normalized)\n'})}),"\n",(0,s.jsx)(e.h3,{id:"lidar-lidar-sensor",children:"LiDAR (LIDAR) Sensor"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"LiDAR Configuration"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from omni.isaac.range_sensor import _range_sensor\n\n# Add LiDAR sensor\nlidar_prim = create_prim(\n    prim_path="/World/Robot/LiDAR",\n    prim_type="Lidar",\n    translation=np.array([0, 0, 0.2]),  # 20cm above robot base\n    attributes={\n        "minRange": 0.4,  # 40cm minimum range\n        "maxRange": 100.0,  # 100m maximum range\n        "horizontalFov": 360.0,  # 360-degree scan\n        "horizontalResolution": 1.0,  # 1-degree angular resolution\n        "rotationRate": 10.0,  # 10 Hz scan rate\n    }\n)\n\n# Read LiDAR data\nlidar_interface = _range_sensor.acquire_lidar_sensor_interface()\ndepth_data = lidar_interface.get_linear_depth_data("/World/Robot/LiDAR")\nprint(f"LiDAR scan: {len(depth_data)} points")\n'})}),"\n",(0,s.jsx)(e.h3,{id:"imu-inertial-measurement-unit",children:"IMU (Inertial Measurement Unit)"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"IMU Configuration"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from omni.isaac.sensor import IMUSensor\n\n# Create IMU attached to robot base\nimu = IMUSensor(\n    prim_path="/World/Robot/IMU",\n    name="imu_sensor",\n    frequency=100,  # 100 Hz update rate\n    translation=np.array([0, 0, 0]),  # At robot\'s center of mass\n)\n\nimu.initialize()\n\n# Read IMU data\nimu_data = imu.get_current_frame()\nlinear_acceleration = imu_data["lin_acc"]  # 3D acceleration (m/s\xb2)\nangular_velocity = imu_data["ang_vel"]  # 3D angular velocity (rad/s)\norientation = imu_data["orientation"]  # Quaternion (w, x, y, z)\n\nprint(f"Acceleration: {linear_acceleration}")\nprint(f"Angular Velocity: {angular_velocity}")\n'})}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"ros-2-integration",children:"ROS 2 Integration"}),"\n",(0,s.jsxs)(e.p,{children:["Isaac Sim integrates with ROS 2 via ",(0,s.jsx)(e.strong,{children:"OmniGraph"}),", a visual node-based scripting system."]}),"\n",(0,s.jsx)(e.h3,{id:"setting-up-ros-2-bridge",children:"Setting Up ROS 2 Bridge"}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 1: Enable ROS 2 Extension"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["In Isaac Sim, go to ",(0,s.jsx)(e.strong,{children:"Window \u2192 Extensions"})]}),"\n",(0,s.jsxs)(e.li,{children:["Search for ",(0,s.jsx)(e.strong,{children:'"ROS 2 Bridge"'})]}),"\n",(0,s.jsx)(e.li,{children:"Enable the extension (may require restart)"}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 2: Create an OmniGraph"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Go to ",(0,s.jsx)(e.strong,{children:"Window \u2192 Visual Scripting \u2192 Action Graph"})]}),"\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"New Action Graph"})]}),"\n",(0,s.jsxs)(e.li,{children:["Name it ",(0,s.jsx)(e.code,{children:"ROS2_Bridge"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 3: Add ROS 2 Publisher Nodes"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["In the Action Graph editor, right-click \u2192 ",(0,s.jsx)(e.strong,{children:"Add Node"})]}),"\n",(0,s.jsxs)(e.li,{children:["Search for ",(0,s.jsx)(e.strong,{children:'"ROS2 Publish Clock"'})," and add it (publishes ",(0,s.jsx)(e.code,{children:"/clock"})," topic)"]}),"\n",(0,s.jsxs)(e.li,{children:["Add ",(0,s.jsx)(e.strong,{children:'"On Playback Tick"'})," node (triggers every simulation step)"]}),"\n",(0,s.jsxs)(e.li,{children:["Connect ",(0,s.jsx)(e.strong,{children:"On Playback Tick"})," \u2192 ",(0,s.jsx)(e.strong,{children:"ROS2 Publish Clock"})," (triggers clock publishing)"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 4: Add Camera Publisher"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Add ",(0,s.jsx)(e.strong,{children:'"ROS2 Camera Helper"'})," node"]}),"\n",(0,s.jsxs)(e.li,{children:["Configure:","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Camera Prim Path"}),": ",(0,s.jsx)(e.code,{children:"/World/Camera"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Topic Name"}),": ",(0,s.jsx)(e.code,{children:"/camera/image_raw"})]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Frame ID"}),": ",(0,s.jsx)(e.code,{children:"camera_frame"})]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["Connect ",(0,s.jsx)(e.strong,{children:"On Playback Tick"})," \u2192 ",(0,s.jsx)(e.strong,{children:"ROS2 Camera Helper"})]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:(0,s.jsx)(e.strong,{children:"Step 5: Verify ROS 2 Topics"})}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:["Click ",(0,s.jsx)(e.strong,{children:"Play"})," in Isaac Sim"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"In a terminal, run:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"ros2 topic list\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Output"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{children:"/clock\n/camera/image_raw\n/camera/camera_info\n"})}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsx)(e.p,{children:"Echo camera topic:"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"ros2 topic echo /camera/image_raw --no-arr\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h3,{id:"ros-2-control-example-python",children:"ROS 2 Control Example (Python)"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Publish Joint Commands from ROS 2"}),":"]}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:"#!/usr/bin/env python3\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import JointState\n\nclass RobotController(Node):\n    def __init__(self):\n        super().__init__('robot_controller')\n        self.publisher = self.create_publisher(JointState, '/joint_command', 10)\n        self.timer = self.create_timer(0.1, self.publish_commands)  # 10 Hz\n\n    def publish_commands(self):\n        msg = JointState()\n        msg.header.stamp = self.get_clock().now().to_msg()\n        msg.name = ['wheel_left_joint', 'wheel_right_joint']\n        msg.position = [0.0, 0.0]\n        msg.velocity = [2.0, 2.0]  # Move forward at 2 rad/s\n        msg.effort = []\n\n        self.publisher.publish(msg)\n        self.get_logger().info('Publishing joint commands')\n\ndef main():\n    rclpy.init()\n    controller = RobotController()\n    rclpy.spin(controller)\n    controller.destroy_node()\n    rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Subscribe to Joint Commands in Isaac Sim (OmniGraph)"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Add ",(0,s.jsx)(e.strong,{children:'"ROS2 Subscribe Joint State"'})," node in Action Graph"]}),"\n",(0,s.jsxs)(e.li,{children:["Set ",(0,s.jsx)(e.strong,{children:"Topic Name"}),": ",(0,s.jsx)(e.code,{children:"/joint_command"})]}),"\n",(0,s.jsxs)(e.li,{children:["Add ",(0,s.jsx)(e.strong,{children:'"Articulation Controller"'})," node"]}),"\n",(0,s.jsxs)(e.li,{children:["Connect ",(0,s.jsx)(e.strong,{children:"ROS2 Subscribe Joint State"})," output \u2192 ",(0,s.jsx)(e.strong,{children:"Articulation Controller"})," input"]}),"\n",(0,s.jsxs)(e.li,{children:["Set ",(0,s.jsx)(e.strong,{children:"Target Prim"}),": ",(0,s.jsx)(e.code,{children:"/World/Robot"})]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"synthetic-data-generation",children:"Synthetic Data Generation"}),"\n",(0,s.jsxs)(e.p,{children:["Isaac Sim's ",(0,s.jsx)(e.strong,{children:"Replicator"})," API enables automated generation of labeled datasets for machine learning."]}),"\n",(0,s.jsx)(e.h3,{id:"example-generate-rgb--semantic-segmentation-data",children:"Example: Generate RGB + Semantic Segmentation Data"}),"\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-python",children:'from isaacsim import SimulationApp\nsimulation_app = SimulationApp({"headless": False})\n\nimport omni.replicator.core as rep\nfrom omni.isaac.core import World\nimport numpy as np\n\n# Create world with objects\nworld = World()\nworld.scene.add_default_ground_plane()\n\n# Add multiple objects for dataset\nfor i in range(10):\n    rep.create.sphere(\n        position=(np.random.uniform(-2, 2), np.random.uniform(-2, 2), 0.5),\n        radius=0.2,\n        semantics=[("class", "ball")]  # Semantic label\n    )\n\n# Create camera\ncamera = rep.create.camera(position=(0, 0, 3), look_at=(0, 0, 0))\n\n# Attach writer to save data\nwriter = rep.WriterRegistry.get("BasicWriter")\nwriter.initialize(output_dir="synthetic_data", rgb=True, semantic_segmentation=True)\n\n# Render and save frames\nrep.orchestrator.run()\n\nwith rep.trigger.on_frame(num_frames=100):  # Generate 100 frames\n    with camera:\n        rep.randomizer.scatter_2d(\n            surface_prims=["/World/GroundPlane"],\n            check_for_collisions=True\n        )\n    rep.randomizer.light(\n        min_intensity=1000,\n        max_intensity=5000,\n        temperature=(4000, 7000)  # Color temperature variation\n    )\n\nrep.orchestrator.step()\nsimulation_app.close()\n'})}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Output"}),": ",(0,s.jsx)(e.code,{children:"synthetic_data/"})," directory contains:"]}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"rgb_0000.png"}),", ",(0,s.jsx)(e.code,{children:"rgb_0001.png"}),", ... (RGB images)"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.code,{children:"semantic_segmentation_0000.png"}),", ... (Segmentation masks with color-coded classes)"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"hands-on-exercises",children:"Hands-On Exercises"}),"\n",(0,s.jsx)(e.h3,{id:"exercise-1-create-a-custom-scene",children:"Exercise 1: Create a Custom Scene"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Goal"}),": Build a simulation environment with multiple objects and lighting."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Instructions"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Create a new USD stage in Isaac Sim"}),"\n",(0,s.jsx)(e.li,{children:"Add a ground plane"}),"\n",(0,s.jsx)(e.li,{children:"Add 5 physics-enabled cubes at different positions"}),"\n",(0,s.jsx)(e.li,{children:"Add a distant light (sun) and a point light (lamp)"}),"\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"Play"})," and observe object dynamics"]}),"\n",(0,s.jsxs)(e.li,{children:["Save the scene as ",(0,s.jsx)(e.code,{children:"custom_scene.usd"})]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Outcome"}),": A functional scene with multiple objects falling and colliding."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"exercise-2-import-a-robot-urdf",children:"Exercise 2: Import a Robot URDF"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Goal"}),": Import a ROS 2 robot model into Isaac Sim."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Instructions"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["Use the URDF Importer (",(0,s.jsx)(e.strong,{children:"Isaac Utils \u2192 Workflows \u2192 URDF Importer"}),")"]}),"\n",(0,s.jsx)(e.li,{children:"Import a robot URDF (e.g., TurtleBot3, UR5, Franka Panda)"}),"\n",(0,s.jsx)(e.li,{children:"Configure import settings (merge fixed joints, self-collision)"}),"\n",(0,s.jsxs)(e.li,{children:["Inspect the generated USD hierarchy in the ",(0,s.jsx)(e.strong,{children:"Stage"})," panel"]}),"\n",(0,s.jsx)(e.li,{children:"Select a joint and examine its properties (type, limits, drive parameters)"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Outcome"}),": Robot appears in the scene with fully articulated joints."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"exercise-3-add-a-camera-sensor",children:"Exercise 3: Add a Camera Sensor"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Goal"}),": Configure an RGB camera and capture images."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Instructions"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["In your scene, add a camera (",(0,s.jsx)(e.strong,{children:"Create \u2192 Camera"}),")"]}),"\n",(0,s.jsx)(e.li,{children:"Position the camera to view your robot"}),"\n",(0,s.jsxs)(e.li,{children:["In ",(0,s.jsx)(e.strong,{children:"Window \u2192 Render Settings"}),", enable ",(0,s.jsx)(e.strong,{children:"RTX Real-Time"})]}),"\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"Play"})," and observe the viewport"]}),"\n",(0,s.jsx)(e.li,{children:'Use the Python API to capture and save a camera frame (see "RGB Camera" code example)'}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Outcome"}),": Camera captures a photorealistic image of the robot."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"exercise-4-publish-camera-data-to-ros-2",children:"Exercise 4: Publish Camera Data to ROS 2"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Goal"}),": Stream camera images to ROS 2 topics."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Instructions"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"Enable the ROS 2 Bridge extension"}),"\n",(0,s.jsxs)(e.li,{children:["Create an Action Graph (",(0,s.jsx)(e.strong,{children:"Window \u2192 Visual Scripting \u2192 Action Graph"}),")"]}),"\n",(0,s.jsxs)(e.li,{children:["Add nodes: ",(0,s.jsx)(e.strong,{children:"On Playback Tick"})," \u2192 ",(0,s.jsx)(e.strong,{children:"ROS2 Camera Helper"})]}),"\n",(0,s.jsxs)(e.li,{children:["Configure ",(0,s.jsx)(e.strong,{children:"ROS2 Camera Helper"}),": set camera path and topic name"]}),"\n",(0,s.jsxs)(e.li,{children:["Click ",(0,s.jsx)(e.strong,{children:"Play"})," in Isaac Sim"]}),"\n",(0,s.jsxs)(e.li,{children:["In a terminal, run:","\n",(0,s.jsx)(e.pre,{children:(0,s.jsx)(e.code,{className:"language-bash",children:"ros2 topic list\nros2 topic echo /camera/image_raw --no-arr\n"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Outcome"}),": Camera images are published to the ",(0,s.jsx)(e.code,{children:"/camera/image_raw"})," topic."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h3,{id:"exercise-5-collect-synthetic-training-data",children:"Exercise 5: Collect Synthetic Training Data"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Goal"}),": Generate a dataset of labeled images for object detection."]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Instructions"}),":"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:'Use the Replicator API to create a scene with 20 spheres (labeled "ball")'}),"\n",(0,s.jsx)(e.li,{children:"Add a camera looking at the scene"}),"\n",(0,s.jsxs)(e.li,{children:["Configure a ",(0,s.jsx)(e.strong,{children:"BasicWriter"})," to save RGB + semantic segmentation"]}),"\n",(0,s.jsx)(e.li,{children:"Generate 50 frames with randomized lighting and object positions"}),"\n",(0,s.jsx)(e.li,{children:"Inspect the output directory for saved images"}),"\n"]}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Expected Outcome"}),": ",(0,s.jsx)(e.code,{children:"synthetic_data/"})," contains 50 RGB images and 50 segmentation masks."]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,s.jsx)(e.p,{children:"After completing this chapter, you should understand:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"USD Scene Composition"}),": Isaac Sim uses USD for scene description, with prims representing objects, lights, cameras, and physics components."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"URDF Import"}),": Import ROS 2 robot models (URDF) into Isaac Sim via the URDF Importer, which converts them to USD with physics-enabled articulations."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Sensor Simulation"}),": Isaac Sim supports RGB cameras, depth cameras, LiDAR, IMU, and force sensors with realistic noise models and configurable parameters."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"ROS 2 Integration"}),": Use OmniGraph to create visual node graphs that bridge Isaac Sim and ROS 2, enabling pub/sub communication and robot control."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Synthetic Data Generation"}),": The Replicator API automates creation of labeled datasets (RGB, depth, segmentation) with domain randomization for robust ML training."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Python API"}),": Programmatic scene creation, robot control, and data collection enable reproducible experiments and large-scale automation."]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:["\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Photorealistic Rendering"}),": RTX ray-tracing provides visually accurate simulations for testing computer vision algorithms under diverse lighting conditions."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.hr,{}),"\n",(0,s.jsx)(e.h2,{id:"navigation",children:"Navigation"}),"\n",(0,s.jsxs)(e.p,{children:[(0,s.jsx)(e.strong,{children:"Previous Chapter"}),": ",(0,s.jsx)(e.a,{href:"/docs/module-3-isaac/intro-isaac",children:"Introduction to NVIDIA Isaac"}),"\n",(0,s.jsx)(e.strong,{children:"Next Chapter"}),": ",(0,s.jsx)(e.a,{href:"/docs/module-3-isaac/isaac-gym-rl",children:"Reinforcement Learning with Isaac Gym"})]})]})}function h(n={}){const{wrapper:e}={...(0,t.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}}}]);